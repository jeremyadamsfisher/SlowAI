<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="We need some principles from calculus and linear algebra">

<title>slowai - Calculus and Backprop</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="slowai - Calculus and Backprop">
<meta property="og:description" content="We need some principles from calculus and linear algebra">
<meta property="og:image" content="https://jeremy.github.io/slowai/../images/conveyer_belt.png">
<meta property="og:site-name" content="slowai">
<meta property="og:image:height" content="566">
<meta property="og:image:width" content="990">
<meta name="twitter:title" content="slowai - Calculus and Backprop">
<meta name="twitter:description" content="We need some principles from calculus and linear algebra">
<meta name="twitter:image" content="https://jeremy.github.io/slowai/../images/conveyer_belt.png">
<meta name="twitter:image-height" content="566">
<meta name="twitter:image-width" content="990">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">slowai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jeremy/slowai" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./calculus.html">Calculus and Backprop</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SlowAI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diving_deeper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Diving Deeper</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diving_deeper_homework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Diving Deeper, homework</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./calculus.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Calculus and Backprop</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./minibatch_training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Minibatch training</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data and visualizations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolutions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./autoencoders.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autoencoders</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./activations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Activation Statistics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./initializations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Initializations</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#power-rule" id="toc-power-rule" class="nav-link active" data-scroll-target="#power-rule">Power Rule</a></li>
  <li><a href="#chain-rule" id="toc-chain-rule" class="nav-link" data-scroll-target="#chain-rule">Chain Rule</a></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural Networks</a>
  <ul>
  <li><a href="#basic-architecture" id="toc-basic-architecture" class="nav-link" data-scroll-target="#basic-architecture">Basic architecture</a></li>
  <li><a href="#mnistdatamodule" id="toc-mnistdatamodule" class="nav-link" data-scroll-target="#mnistdatamodule">MNISTDataModule</a></li>
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error">Mean Squared Error</a></li>
  <li><a href="#linear-layer" id="toc-linear-layer" class="nav-link" data-scroll-target="#linear-layer">Linear layer</a>
  <ul class="collapse">
  <li><a href="#for-x" id="toc-for-x" class="nav-link" data-scroll-target="#for-x">For <span class="math inline">\(X\)</span>…</a></li>
  <li><a href="#for-w" id="toc-for-w" class="nav-link" data-scroll-target="#for-w">For <span class="math inline">\(W\)</span>…</a></li>
  <li><a href="#for-b" id="toc-for-b" class="nav-link" data-scroll-target="#for-b">For <span class="math inline">\(b\)</span>…</a></li>
  </ul></li>
  <li><a href="#relu" id="toc-relu" class="nav-link" data-scroll-target="#relu">ReLU</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/jeremy/slowai/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Calculus and Backprop</h1>
</div>

<div>
  <div class="description">
    We need some principles from calculus and linear algebra
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>Adapted from:</p>
<ul>
<li><a href="https://youtu.be/_xIzPbCgutY?si=_j757wC5ed44lDk7">https://youtu.be/_xIzPbCgutY?si=_j757wC5ed44lDk7</a></li>
<li><a href="https://youtu.be/vGdB4eI4KBs?si=oRxdtJTpa-MvxaPQ">https://youtu.be/vGdB4eI4KBs?si=oRxdtJTpa-MvxaPQ</a></li>
<li><a href="https://youtu.be/veqj0DsZSXU?si=p9ZkZXNKahN4bbHD">https://youtu.be/veqj0DsZSXU?si=p9ZkZXNKahN4bbHD</a></li>
</ul>
<p>The better calculus pedagogy is the calculus of infintesimals, that is: assume <span class="math inline">\(f'(x) = \frac{f(x + \Delta x)-f(x)}{\Delta x}\)</span> like normal and ignore second order infinitesimals (i.e., infinitesimals of infinitesimals). By doing so, the main rules of arithmetic suddenly also apply to calculus. For example:</p>
<section id="power-rule" class="level3">
<h3 class="anchored" data-anchor-id="power-rule">Power Rule</h3>
<p><span class="math display">\[
\begin{align*}
\frac{\Delta}{\Delta x} x^2 &amp; = \frac{(x + \Delta x)^2 - x^2}{\Delta x} \\
    &amp; = \frac{x^2 + 2 x \Delta x + \Delta x^2 - x^2}{\Delta x} \\
    &amp; = \frac{2 x \Delta x + \Delta x^2}{\Delta x} \\
    &amp; = \frac{2 x \Delta x}{\Delta x} \\
    &amp; = 2x
\end{align*}
\]</span></p>
<p>(Fundamental theorem, commutativity, cancelling terms in numerator, second rule, cancelling shared term in numerator and denominator.)</p>
</section>
<section id="chain-rule" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule">Chain Rule</h3>
<p><span class="math display">\[
\begin{align*}
\frac{\Delta y}{\Delta x} = \frac{\Delta y}{\Delta u} \left( \frac{\Delta u}{\Delta x} \right)
\end{align*}
\]</span></p>
<p>(Shared term in numerator and denominator.)</p>
<p>This is simple arithmetic! For a geometric interpretation, imagine a conveyer belt system, where a motor is connected to A, pulling B and C. Suppose A has a circumference twice of B, and B twice of C. The rate of rotation of C is <span class="math inline">\(2 \times 2=4\)</span>X that of A.</p>
<p><img src="../images/conveyer_belt.png" class="img-fluid"></p>
<p>This corresponds to the system of equations:</p>
<p><span class="math display">\[
\begin{align}
\frac{\Delta C}{\Delta B} &amp;= 2\\
\frac{\Delta B}{\Delta A} &amp;= 2\\
\therefore \frac{\Delta C}{\Delta A} &amp;= \frac{\Delta C}{\Delta B} \left( \frac{\Delta B}{\Delta A} \right) = 2 \times 2 =4 \\
\end{align}
\]</span></p>
<p>If these functions were non-linear, imagine the circumferences of these “functions” changing.</p>
<p>https://webspace.ship.edu/msrenault/geogebracalculus/derivative_intuitive_chain_rule.html</p>
</section>
<section id="neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks">Neural Networks</h2>
<p>Suppose we wanted to model this function with a neural network.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x <span class="op">-</span> <span class="fl">2.5</span>) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>ax.plot(x, y)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-2-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>A single line wouldn’t be especially adequate for this. (The sum of lines is just a line.) But what about the sum of rectified lines?</p>
<div class="cell" data-scrolled="true" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> np.clip(<span class="op">-</span><span class="dv">3</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">2</span>), a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>y2 <span class="op">=</span> np.clip(<span class="dv">3</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">3</span>), a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>y3 <span class="op">=</span> np.clip(<span class="dv">6</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">5</span>), a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>fig, (ax0, ax1) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">3</span>))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y1)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y2)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y3)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ax1.plot(x, y)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>ax1.plot(x, y1 <span class="op">+</span> y2 <span class="op">+</span> y3)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-3-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is the idea of neural networks (except, instead of lines, we’re dealing with hyperplanes).</p>
<section id="basic-architecture" class="level3">
<h3 class="anchored" data-anchor-id="basic-architecture">Basic architecture</h3>
<p>Let’s consider a specific problem. Suppose we wanted to classify digits with a simple neural network.</p>
<hr>
<p><a href="https://github.com/jeremy/slowai/blob/main/slowai/calculus.py#L25" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="mnistdatamodule" class="level3">
<h3 class="anchored" data-anchor-id="mnistdatamodule">MNISTDataModule</h3>
<blockquote class="blockquote">
<pre><code> MNISTDataModule (bs=128)</code></pre>
</blockquote>
<p>A DataModule standardizes the training, val, test splits, data preparation and transforms. The main advantage is consistent data splits, data preparation and transforms across models.</p>
<p>Example::</p>
<pre><code>import lightning as L
import torch.utils.data as data
from lightning.pytorch.demos.boring_classes import RandomDataset

class MyDataModule(L.LightningDataModule):
    def prepare_data(self):
        # download, IO, etc. Useful with shared filesystems
        # only called on 1 GPU/TPU in distributed
        ...

    def setup(self, stage):
        # make assignments here (val/train/test split)
        # called on every process in DDP
        dataset = RandomDataset(1, 100)
        self.train, self.val, self.test = data.random_split(
            dataset, [80, 10, 10], generator=torch.Generator().manual_seed(42)
        )

    def train_dataloader(self):
        return data.DataLoader(self.train)

    def val_dataloader(self):
        return data.DataLoader(self.val)

    def test_dataloader(self):
        return data.DataLoader(self.test)

    def teardown(self):
        # clean up state after the trainer stops, delete files...
        # called on every process in DDP
        ...</code></pre>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dm <span class="op">=</span> MNISTDataModule()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>dm.setup()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>X_trn, y_true <span class="op">=</span> dm.as_matrix(<span class="st">"trn"</span>, as_<span class="op">=</span><span class="st">"numpy"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>show_image(X_trn[<span class="dv">0</span>, ...].squeeze())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It’s a bit cleaner to deal with images as vectors for this exercise.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X_trn <span class="op">=</span> rearrange(X_trn, <span class="st">"b h w -&gt; b (h w)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Say we wanted to classify a digit as a “seven” (or not) based on a single pixel. A trained linear model would find some coefficient and you would draw some line dividing sevens from non-sevens.</p>
<p>Of course, this is pretty limiting. What if this surface had a lot of curvature?</p>
<div class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> <span class="op">-</span><span class="fl">0.95</span> <span class="op">*</span> x <span class="op">+</span> <span class="fl">1.1</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x, y_t, label<span class="op">=</span><span class="st">"True"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, y_pred, label<span class="op">=</span><span class="st">"Pred"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Pixel Intensity"</span>, ylabel<span class="op">=</span><span class="st">"P(Seven)"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>fig.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>How do fit the sum of rectified lines like before?</p>
<p>To make this more interesting, let’s consider using all pixels, for all images.</p>
<p>Let’s define some parameters and helpers.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu(x):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.clip(x, a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>n, m <span class="op">=</span> X_trn.shape</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>nh <span class="op">=</span> <span class="dv">50</span>  <span class="co"># num. hidden dimensions</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>n, m</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(60000, 784)</code></pre>
</div>
</div>
<p>Our results are going to be non-sense here, but this gives us the right dimensions for everything.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>W0 <span class="op">=</span> np.random.randn(m, nh)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>b0 <span class="op">=</span> np.zeros(nh)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> np.random.randn(nh, <span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> np.zeros(<span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>l0 <span class="op">=</span> X_trn <span class="op">@</span> W0 <span class="op">+</span> b0</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>l1 <span class="op">=</span> relu(l0)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> l1 <span class="op">@</span> W1 <span class="op">+</span> b1</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>y_pred[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([[ 20.64558787],
       [-17.49943048],
       [-40.15099661],
       [-20.96064613],
       [-28.6419001 ]])</code></pre>
</div>
</div>
<p>Let’s compute an regression loss to get the model to predict the label. (This isn’t formally apropriate but it gives us the intuition.)</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>y_pred.shape, y_true.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>((60000, 1), (60000,))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> y_pred.T <span class="op">-</span> y_true</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> (diff<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>mse</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>1349.5939954853677</code></pre>
</div>
</div>
<p>Eventually, at the end of the forward pass, we end up with a <strong>single number</strong>. We compute the loss for each example in the batch and take the batchwise mean or sum of the loss. Then, we use this along with the gradients with respect to each parameter to update the weights,</p>
<p>Let’s calculate these derivates, one by one 🤩</p>
</section>
<section id="mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error">Mean Squared Error</h3>
<p>First, we need to determine the gradient of the loss with respect to it’s input.</p>
<p><span class="math display">\[MSE = \frac{ \sum_{i=1}^{N} ( y^i-a^i )^2 }{N}\]</span></p>
<p>This function composes an inner difference function and an outer square function. By the chain rule:</p>
<p><span class="math display">\[
\frac{d}{dx} f(g(x,y)) = f'(g(x,y)) g'(x,y)
\]</span></p>
<p>Let <span class="math inline">\(g(x,y) = x-y\)</span> and <span class="math inline">\(f(x) = \frac{x^2}{n}\)</span></p>
<p>Thus, <span class="math inline">\(\frac{d}{dx} g(x,y)=\frac{dx}{dx} - \frac{dy}{dx}=1\)</span> and <span class="math display">\[
\begin{align*}
f'(g(x, y)) &amp; = f'((x-y)^2 / n) \\
            &amp; = f'((x^2 - 2xy + y^2)/n) \\
            &amp; = (2x - 2y) / n
\end{align*}
\]</span></p>
<p>Let’s verify:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> n <span class="op">==</span> <span class="dv">60000</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> sympy.symbols(<span class="st">"x y"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>sympy.diff(((x <span class="op">-</span> y) <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> n, x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<p><span class="math inline">\(\displaystyle \frac{x}{30000} - \frac{y}{30000}\)</span></p>
</div>
</div>
<p>Great. Now, in code:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> T:</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Wrapper for numpy arrays to help store a gradient"""</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    value: Any</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    g: Any <span class="op">=</span> <span class="va">None</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getattr__</span>(<span class="va">self</span>, t):</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">getattr</span>(<span class="va">self</span>.value, t)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i):</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.value[i]</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> v(<span class="va">self</span>):</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.value</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_grad(y_pred: T, y_true: np.array):</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    diff <span class="op">=</span> y_pred.squeeze() <span class="op">-</span> y_true</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    y_pred_g <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> diff <span class="op">/</span> n</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    y_pred.g <span class="op">=</span> y_pred_g[:, <span class="va">None</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="linear-layer" class="level3">
<h3 class="anchored" data-anchor-id="linear-layer">Linear layer</h3>
<p>For a linear layer, the gradient is derived like so:</p>
<p>Let <span class="math inline">\(L = l(N)\)</span> and <span class="math inline">\(N_{W,b}(X)\)</span> is a neural network with parameters <span class="math inline">\(W, b\)</span> and an input <span class="math inline">\(X\)</span>. We want to compute the partial derivates of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(W\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(X\)</span> to pass upstream and manipulate the parameters. Therefore, we want to compute the chain rule:</p>
<section id="for-x" class="level4">
<h4 class="anchored" data-anchor-id="for-x">For <span class="math inline">\(X\)</span>…</h4>
<p>By the chain rule:</p>
<p><span class="math display">\[\frac{\partial L}{\partial X} = \frac{\partial L}{\partial N} \cdot \frac{\partial N}{\partial X}\]</span></p>
<ul>
<li><span class="math inline">\(\frac{\partial L}{\partial N}\)</span> is the change of the loss with respect to the output of the linear layer, <code>out.g</code>.</li>
<li><span class="math inline">\(\frac{\partial N}{\partial X}\)</span> is the change of the output with respect to <span class="math inline">\(X\)</span>, or <span class="math inline">\(w.T\)</span>, which is simply direction in which <code>x</code> was manipulated</li>
</ul>
</section>
<section id="for-w" class="level4">
<h4 class="anchored" data-anchor-id="for-w">For <span class="math inline">\(W\)</span>…</h4>
<p>This is slightly more complicated. The weight gradient combines the mapping of the specific weights that influence each output dimension (<code>inp.T</code>) with the contribution of each output dimension to the loss (<code>out.g</code>).</p>
<p>By the chain rule, for the <span class="math inline">\(j\)</span>th parameter of <span class="math inline">\(W\)</span>, <span class="math display">\[
\begin{align*}
\frac{\partial L}{\partial W_j} = \frac{\partial L}{\partial N} \cdot \frac{\partial N}{\partial W_j}
= \sum_{k=1}^{||N||} \frac{\partial L}{\partial n_k} \cdot \frac{\partial n_k}{\partial W_j}
\end{align*}
\]</span></p>
<p>By the same logic where we determined that <span class="math inline">\(\frac{\partial N}{\partial X}\)</span> is <span class="math inline">\(W\)</span>, we can say that <span class="math inline">\(\frac{\partial n_k}{\partial W_j}\)</span> is <span class="math inline">\(x_j^i\)</span>. You can also think about this mathematically: what is the derivative of <span class="math inline">\(WX+b\)</span> with respect to <span class="math inline">\(W_j\)</span>? This is the <span class="math inline">\(j\)</span>th element of the <span class="math inline">\(i\)</span>th example.<span class="math display">\[
\sum_{k=1}^{||N||} \frac{\partial L}{\partial n_k} \cdot \frac{\partial n_i}{\partial W_j} = \sum_{k=1}^{||N||} \frac{\partial L}{\partial n_k} x_j^i
\]</span></p>
<p>Because <span class="math inline">\(W\)</span> is a multivariate function, it’s loss Jacobian is defined like so <span class="math display">\[
\frac{\partial L}{\partial W} = \begin{bmatrix}
\frac{\partial L}{\partial W_{1}} \\
\frac{\partial L}{\partial W_{2}} \\
\vdots \\
\frac{\partial L}{\partial W_{d}}
\end{bmatrix} = \begin{bmatrix}
\frac{\partial L}{\partial n_1} x_1^1 &amp;+ \dots &amp;+ \frac{\partial L}{\partial n_{||N||}} x^{||N||}_1 \\
\vdots &amp; \ddots &amp; \vdots \\
\frac{\partial L}{\partial n_1} x_d^1 &amp;+ \dots &amp;+ \frac{\partial L}{\partial n_{||N||}} x^{||N||}_d
\end{bmatrix}
\]</span></p>
<p>Factoring out all the <span class="math inline">\(x\)</span>’s from the partial derivates gives us the final expression: <span class="math display">\[
\frac{\partial L}{\partial W} = \begin{bmatrix}
x_1^1 &amp; \dots &amp; x^{||N||}_1 \\
\vdots &amp; \ddots &amp; \vdots \\
x_d^1 &amp; \dots &amp; x^{||N||}_d
\end{bmatrix}  \begin{bmatrix}
\frac{\partial L}{\partial n_{1}} \\
\vdots \\
\frac{\partial L}{\partial n_{||N||}} \\
\end{bmatrix} = X^T \frac{\partial L}{\partial N}
\]</span></p>
<p>More info: https://nasheqlbrm.github.io/blog/posts/2021-11-13-backward-pass.html</p>
</section>
<section id="for-b" class="level4">
<h4 class="anchored" data-anchor-id="for-b">For <span class="math inline">\(b\)</span>…</h4>
<p>The gradient of the bias simply consolidates the gradients from from all the output dimensions</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lin_grad(inp, out, w, b):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    inp.g <span class="op">=</span> out.g <span class="op">@</span> w.T</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    w.g <span class="op">=</span> inp.v.T <span class="op">@</span> out.g</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    b.g <span class="op">=</span> out.g.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="relu" class="level3">
<h3 class="anchored" data-anchor-id="relu">ReLU</h3>
<p>For ReLU, we pass the upstream gradient downstream for any dimensions that contributed to the upstream signal. Note that this is an element-wise operation because the layer operates only on specific elements and has no global behavior.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu_grad(inp, out):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    inp.g <span class="op">=</span> (inp.value <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">float</span>) <span class="op">*</span> out.g</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Putting it all together:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># "Tensorize" the weights, biases and outputs</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>tensors <span class="op">=</span> (y_pred, W1, b1, l1, W0, b0, l0, X_trn)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>ty_pred, tW1, tb1, tl1, tW0, tb0, tl0, tX_trn <span class="op">=</span> <span class="bu">map</span>(T, tensors)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>mse_grad(ty_pred, y_true)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>ty_pred.g[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>array([[ 0.00052152],
       [-0.00058331],
       [-0.0014717 ],
       [-0.00073202],
       [-0.00125473]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>mse_grad(ty_pred, y_true)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>lin_grad(tl1, ty_pred, tW1, tb1)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>relu_grad(tl0, tl1)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>lin_grad(tX_trn, tl0, tW0, tb0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Verify with PyTorch</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Port layers</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>pt_lin0 <span class="op">=</span> nn.Linear(m, nh)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> pt_lin0.weight.data.dtype</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>pt_lin0.weight.data <span class="op">=</span> torch.from_numpy(tW0.v.T).to(dtype)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>pt_lin0.bias.data <span class="op">=</span> torch.from_numpy(tb0.v).to(dtype)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>pt_lin1 <span class="op">=</span> nn.Linear(nh, <span class="dv">1</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>pt_lin1.weight.data <span class="op">=</span> torch.from_numpy(tW1.T).to(dtype)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>pt_lin1.bias.data <span class="op">=</span> torch.from_numpy(tb1.v).to(dtype)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> pt_lin0(torch.from_numpy(X_trn).to(dtype))</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> F.relu(logits)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> pt_lin1(logits)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> F.mse_loss(</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    logits.squeeze(),</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    torch.from_numpy(y_true).<span class="bu">float</span>(),</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Backward pass</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w, b, layer <span class="kw">in</span> [</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    (tW0, tb0, pt_lin0),</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    (tW1, tb1, pt_lin1),</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>]:</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> torch.isclose(</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>        torch.from_numpy(w.g.T).<span class="bu">float</span>(),</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>        layer.weight.grad,</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>        atol<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>    ).<span class="bu">all</span>()</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> torch.isclose(</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>        torch.from_numpy(b.g.T).<span class="bu">float</span>(),</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>        layer.bias.grad,</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>        atol<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>    ).<span class="bu">all</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s refactor these as classes.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Module:</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, <span class="op">*</span>x):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.inp <span class="op">=</span> x</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> <span class="va">self</span>.forward(<span class="op">*</span>x)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(<span class="va">self</span>.out, (np.ndarray,)):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.out <span class="op">=</span> T(<span class="va">self</span>.out)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ReLu(Module):</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: T):</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> relu(x)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        (x,) <span class="op">=</span> <span class="va">self</span>.inp</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        relu_grad(x, <span class="va">self</span>.out)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear(Module):</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, h_in, h_out):</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> T(np.random.randn(h_in, h_out))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> T(np.zeros(h_out))</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> T(x <span class="op">@</span> <span class="va">self</span>.W.v <span class="op">+</span> <span class="va">self</span>.b.v)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        (x,) <span class="op">=</span> <span class="va">self</span>.inp</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        lin_grad(x, <span class="va">self</span>.out, <span class="va">self</span>.W, <span class="va">self</span>.b)</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MSE(Module):</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, y_pred, y_true):</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ((y_pred.squeeze() <span class="op">-</span> y_true) <span class="op">**</span> <span class="dv">2</span>).mean()</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        y_pred, y_true <span class="op">=</span> <span class="va">self</span>.inp</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        mse_grad(y_pred, y_true)</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(Module):</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers, criterion):</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> layers</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion <span class="op">=</span> criterion</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, y_pred):</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> l(x)</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion(x, y_pred)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion.backward()</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">reversed</span>(<span class="va">self</span>.layers):</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>            l.backward()</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MLP([Linear(m, nh), ReLu(), Linear(nh, <span class="dv">1</span>)], criterion<span class="op">=</span>MSE())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model(tX_trn, y_true)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>model.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is quite a bit cleaner!</p>
<p>By the rules of FastAI, we can now use the <code>torch.nn.Module</code> classes which is the equivalent in PyTorch.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
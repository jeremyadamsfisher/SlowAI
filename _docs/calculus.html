<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="We need some principles from calculus and linear algebra">

<title>slowai - Calculus and Backprop</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="slowai - Calculus and Backprop">
<meta property="og:description" content="We need some principles from calculus and linear algebra">
<meta property="og:image" content="https://jeremy.github.io/slowai/03_calculus_files/figure-html/cell-2-output-1.png">
<meta property="og:site-name" content="slowai">
<meta property="og:image:height" content="274">
<meta property="og:image:width" content="284">
<meta name="twitter:title" content="slowai - Calculus and Backprop">
<meta name="twitter:description" content="We need some principles from calculus and linear algebra">
<meta name="twitter:image" content="https://jeremy.github.io/slowai/03_calculus_files/figure-html/cell-2-output-1.png">
<meta name="twitter:image-height" content="274">
<meta name="twitter:image-width" content="284">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">slowai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jeremy/slowai" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./calculus.html">Calculus and Backprop</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SlowAI</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Utilities</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diving_deeper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Diving Deeper</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diving_deeper_homework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Diving Deeper, homework</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Clustering</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./calculus.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Calculus and Backprop</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./minibatch_training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Minibatch training</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data and visualizations</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./convs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolutions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./autoencoders.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autoencoders</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./learner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./activations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Activation Statistics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./initializations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Initializations</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#power-rule" id="toc-power-rule" class="nav-link active" data-scroll-target="#power-rule">Power Rule</a></li>
  <li><a href="#chain-rule" id="toc-chain-rule" class="nav-link" data-scroll-target="#chain-rule">Chain Rule</a></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural Networks</a>
  <ul>
  <li><a href="#basic-architecture" id="toc-basic-architecture" class="nav-link" data-scroll-target="#basic-architecture">Basic architecture</a></li>
  <li><a href="#mnistdatamodule" id="toc-mnistdatamodule" class="nav-link" data-scroll-target="#mnistdatamodule">MNISTDataModule</a></li>
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error">Mean Squared Error</a></li>
  <li><a href="#linear-layer" id="toc-linear-layer" class="nav-link" data-scroll-target="#linear-layer">Linear layer</a>
  <ul class="collapse">
  <li><a href="#for-x" id="toc-for-x" class="nav-link" data-scroll-target="#for-x">For <span class="math inline">\(X\)</span>‚Ä¶</a></li>
  <li><a href="#for-w" id="toc-for-w" class="nav-link" data-scroll-target="#for-w">For <span class="math inline">\(W\)</span>‚Ä¶</a></li>
  <li><a href="#for-b" id="toc-for-b" class="nav-link" data-scroll-target="#for-b">For <span class="math inline">\(B\)</span>‚Ä¶</a></li>
  </ul></li>
  <li><a href="#relu" id="toc-relu" class="nav-link" data-scroll-target="#relu">ReLU</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/jeremy/slowai/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Calculus and Backprop</h1>
</div>

<div>
  <div class="description">
    We need some principles from calculus and linear algebra
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>Adapted from:</p>
<ul>
<li><a href="https://youtu.be/_xIzPbCgutY?si=_j757wC5ed44lDk7">https://youtu.be/_xIzPbCgutY?si=_j757wC5ed44lDk7</a></li>
<li><a href="https://youtu.be/vGdB4eI4KBs?si=oRxdtJTpa-MvxaPQ">https://youtu.be/vGdB4eI4KBs?si=oRxdtJTpa-MvxaPQ</a></li>
<li><a href="https://youtu.be/veqj0DsZSXU?si=p9ZkZXNKahN4bbHD">https://youtu.be/veqj0DsZSXU?si=p9ZkZXNKahN4bbHD</a></li>
</ul>
<p>The better calculus pedagogy is the calculus of infintesimals, that is: assume <span class="math inline">\(f'(x) = \frac{f(x + \Delta x)-f(x)}{\Delta x}\)</span> like normal and ignore second order infinitesimals (i.e., infinitesimals of infinitesimals). By doing so, the main rules of arithmetic suddenly also apply to calculus. For example:</p>
<section id="power-rule" class="level3">
<h3 class="anchored" data-anchor-id="power-rule">Power Rule</h3>
<p><span class="math display">\[
\begin{align*}
\frac{\Delta}{\Delta x} x^2 &amp; = \frac{(x + \Delta x)^2 - x^2}{\Delta x} \\
    &amp; = \frac{x^2 + 2 x \Delta x + \Delta x^2 - x^2}{\Delta x} \\
    &amp; = \frac{2 x \Delta x + \Delta x^2}{\Delta x} \\
    &amp; = \frac{2 x \Delta x}{\Delta x} \\
    &amp; = 2x
\end{align*}
\]</span></p>
<p>(Fundamental theorem, commutativity, cancelling terms in numerator, second rule, cancelling shared term in numerator and denominator.)</p>
</section>
<section id="chain-rule" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule">Chain Rule</h3>
<p><span class="math display">\[
\begin{align*}
\frac{\Delta y}{\Delta x} = \frac{\Delta y}{\Delta u} \left( \frac{\Delta u}{\Delta x} \right)
\end{align*}
\]</span></p>
<p>(Shared term in numerator and denominator.)</p>
<p>This is simple arithmetic! For a geometric interpretation, imagine riding a bicycle on a moving sidewalk. If you are cycling at 2 kilometers per hour and the sidewalk was movinig at 2 kilometers per hour, then your overall speed is 4 kilometers per hour.</p>
<p><span class="math display">\[
\begin{align}
\frac{\Delta C}{\Delta B} &amp;= 2\\
\frac{\Delta B}{\Delta A} &amp;= 2\\
\therefore \frac{\Delta C}{\Delta A} &amp;= \frac{\Delta C}{\Delta B} \left( \frac{\Delta B}{\Delta A} \right) = 2 \times 2 =4 \\
\end{align}
\]</span></p>
<p>For non-linear functions, imagine the speed of the sidewalk changing.</p>
<p>For an intuitive demonstration of the chain rule, <a href="https://webspace.ship.edu/msrenault/geogebracalculus/derivative_intuitive_chain_rule.html">click here.</a></p>
</section>
<section id="neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks">Neural Networks</h2>
<p>How does this relate to deep learning? Suppose we wanted to model this function with a neural network.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x <span class="op">-</span> <span class="fl">2.5</span>) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>ax.plot(x, y)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-2-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>A single line wouldn‚Äôt be especially adequate for this. (The sum of lines is just a line.) But what about the sum of rectified lines?</p>
<div class="cell" data-scrolled="true" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> np.clip(<span class="op">-</span><span class="dv">3</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">2</span>), a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>y2 <span class="op">=</span> np.clip(<span class="dv">3</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">3</span>), a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>y3 <span class="op">=</span> np.clip(<span class="dv">6</span> <span class="op">*</span> (x <span class="op">-</span> <span class="dv">5</span>), a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>fig, (ax0, ax1) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">3</span>))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y1)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y2)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>ax0.plot(x, y3)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>ax1.plot(x, y)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>ax1.plot(x, y1 <span class="op">+</span> y2 <span class="op">+</span> y3)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-3-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is the idea of neural networks (except, instead of lines, we‚Äôre dealing with hyperplanes).</p>
<section id="basic-architecture" class="level3">
<h3 class="anchored" data-anchor-id="basic-architecture">Basic architecture</h3>
<p>Let‚Äôs consider a specific problem. Suppose we wanted to classify digits with a simple neural network.</p>
<hr>
<p><a href="https://github.com/jeremy/slowai/blob/main/slowai/calculus.py#L25" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="mnistdatamodule" class="level3">
<h3 class="anchored" data-anchor-id="mnistdatamodule">MNISTDataModule</h3>
<blockquote class="blockquote">
<pre><code> MNISTDataModule (bs=128)</code></pre>
</blockquote>
<p>MNIST data Module</p>
<p>It‚Äôs a bit cleaner to deal with images as vectors for this exercise.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X_trn <span class="op">=</span> rearrange(X_trn, <span class="st">"b h w -&gt; b (h w)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Say we wanted to classify a digit as a ‚Äúseven‚Äù (or not) based on a single pixel. A trained linear model would find some coefficient and you would draw some line dividing sevens from non-sevens.</p>
<p>Of course, this is pretty limiting. What if this surface had a lot of curvature?</p>
<div class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y_t <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> <span class="op">-</span><span class="fl">0.95</span> <span class="op">*</span> x <span class="op">+</span> <span class="fl">1.1</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x, y_t, label<span class="op">=</span><span class="st">"True"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x, y_pred, label<span class="op">=</span><span class="st">"Pred"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>ax.<span class="bu">set</span>(xlabel<span class="op">=</span><span class="st">"Pixel Intensity"</span>, ylabel<span class="op">=</span><span class="st">"P(Seven)"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>fig.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="03_calculus_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>How do fit the sum of rectified lines like before?</p>
<p>To make this more interesting, let‚Äôs consider using all pixels, for all images.</p>
<p>Let‚Äôs define some parameters and helpers.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu(x):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.clip(x, a_min<span class="op">=</span><span class="dv">0</span>, a_max<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>n, m <span class="op">=</span> X_trn.shape</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>nh <span class="op">=</span> <span class="dv">50</span>  <span class="co"># num. hidden dimensions</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>n, m</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(60000, 784)</code></pre>
</div>
</div>
<p>Our results are going to be non-sense here, but this gives us the right dimensions for everything.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>W0 <span class="op">=</span> np.random.randn(m, nh)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>b0 <span class="op">=</span> np.zeros(nh)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> np.random.randn(nh, <span class="dv">1</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> np.zeros(<span class="dv">1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>l0 <span class="op">=</span> X_trn <span class="op">@</span> W0 <span class="op">+</span> b0</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>l1 <span class="op">=</span> relu(l0)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> l1 <span class="op">@</span> W1 <span class="op">+</span> b1</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>y_pred[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([[ -9.87308795],
       [-24.17324311],
       [ 32.42885041],
       [  6.0755439 ],
       [-65.67629667]])</code></pre>
</div>
</div>
<p>Let‚Äôs compute an regression loss to get the model to predict the label. (This isn‚Äôt formally apropriate but it gives us the intuition.)</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>y_pred.shape, y_true.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>((60000, 1), (60000,))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> y_pred.T <span class="op">-</span> y_true</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> (diff<span class="op">**</span><span class="dv">2</span>).mean()</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>mse</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>1979.1768273281134</code></pre>
</div>
</div>
<p>Eventually, at the end of the forward pass, we end up with a <strong>single number</strong>. We compute the loss for each example in the batch and take the batchwise mean or sum of the loss. Then, we use this along with the gradients with respect to each parameter to update the weights,</p>
<p>Let‚Äôs calculate these derivates, one by one ü§©</p>
</section>
<section id="mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error">Mean Squared Error</h3>
<p>First, we need to determine the gradient of the loss with respect to it‚Äôs input.</p>
<p><span class="math display">\[MSE = \frac{ \sum_{i=1}^{N} ( y^i-a^i )^2 }{N}\]</span></p>
<p>This function composes an inner difference function and an outer square function. By the chain rule:</p>
<p><span class="math display">\[
\frac{d}{dx} f(g(x,y)) = f'(g(x,y)) g'(x,y)
\]</span></p>
<p>Let <span class="math inline">\(g(x,y) = x-y\)</span> and <span class="math inline">\(f(x) = \frac{x^2}{n}\)</span></p>
<p>Thus, <span class="math inline">\(\frac{d}{dx} g(x,y)=\frac{dx}{dx} - \frac{dy}{dx}=1\)</span> and <span class="math display">\[
\begin{align*}
f'(g(x, y)) &amp; = f'((x-y)^2 / n) \\
            &amp; = f'((x^2 - 2xy + y^2)/n) \\
            &amp; = (2x - 2y) / n
\end{align*}
\]</span></p>
<p>Let‚Äôs verify:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> n <span class="op">==</span> <span class="dv">60000</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> sympy.symbols(<span class="st">"x y"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>sympy.diff(((x <span class="op">-</span> y) <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> n, x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<p><span class="math inline">\(\displaystyle \frac{x}{30000} - \frac{y}{30000}\)</span></p>
</div>
</div>
<p>Great. Now, to implement this in code, we need a way to store gradients on tensors themselves.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> T:</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Wrapper for numpy arrays to help store a gradient"""</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    value: Any</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    g: Any <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getattr__</span>(<span class="va">self</span>, t):</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">getattr</span>(<span class="va">self</span>.value, t)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i):</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.value[i]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> v(<span class="va">self</span>):</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, we can implement it like so:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_grad(y_pred: T, y_true: np.array):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    diff <span class="op">=</span> y_pred.squeeze() <span class="op">-</span> y_true</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    y_pred_g <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> diff <span class="op">/</span> n</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    y_pred.g <span class="op">=</span> y_pred_g[:, <span class="va">None</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Continuing on with the linear transformation layer, we‚Äôll review the mathematics then implement the code.</p>
</section>
<section id="linear-layer" class="level3">
<h3 class="anchored" data-anchor-id="linear-layer">Linear layer</h3>
<p>For a linear layer, the gradient is derived like so:</p>
<p>Let <span class="math inline">\(L = loss(Y)\)</span> and <span class="math inline">\(Y = WX+B\)</span> be a neural network. We want to compute the partial derivates of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(W\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(X\)</span> to, ultimately, reduce <span class="math inline">\(L\)</span>.</p>
<section id="for-x" class="level4">
<h4 class="anchored" data-anchor-id="for-x">For <span class="math inline">\(X\)</span>‚Ä¶</h4>
<p>Starting with a single, <span class="math inline">\(j\)</span>th parameter of the <span class="math inline">\(i\)</span>th example, <span class="math inline">\(x_j^i\)</span></p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial L}{\partial x_j^i} &amp;= \frac{\partial L}{\partial Y} \cdot \frac{\partial Y}{\partial x_j^i} \\
                                  &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k} \cdot \frac{\partial y^k}{\partial x_j^i}
\end{align*}
\]</span></p>
<p>Note that <span class="math inline">\(\frac{\partial y^k}{\partial x_j^i} = 0\)</span> if <span class="math inline">\(k \neq i\)</span> (i.e., the output of an example passed through the network is not a function of the input of a different example). Therefore,</p>
<p><span class="math display">\[
\begin{align*}
\sum_{k=1}^{N} \frac{\partial L}{\partial y^k} \cdot \frac{\partial y^k}{\partial x_j^i}
&amp;= \frac{\partial L}{\partial y^i} \cdot \frac{\partial y^i}{\partial x_j^i} \\
&amp;= \frac{\partial L}{\partial y^i} \cdot \frac{\partial w_j x_j^i +b}{\partial x_j^i} \\
&amp;= \frac{\partial L}{\partial y^i} w_j
\end{align*}
\]</span></p>
<p>The matrix of derivates for all <span class="math inline">\(d\)</span> parameters (<span class="math inline">\(j \in \{1, ..., d\}\)</span>) and <span class="math inline">\(N\)</span> examples (<span class="math inline">\(i \in \{1, ..., N\}\)</span>) is:</p>
<p><span class="math display">\[
\frac{\partial L}{\partial X} = \begin{bmatrix}
\frac{\partial L}{\partial y^1} w_1 &amp; \dots &amp; \frac{\partial L}{\partial y^1} w_d \\
\frac{\partial L}{\partial y^2} w_1 &amp; \dots &amp; \frac{\partial L}{\partial y^2} w_d \\
\vdots \\
\frac{\partial L}{\partial y^N} w_1 &amp; \dots &amp; \frac{\partial L}{\partial y^N} w_d \\
\end{bmatrix} = \begin{bmatrix}
\frac{\partial L}{\partial y^1} \\
\frac{\partial L}{\partial y^2} \\
\vdots \\
\frac{\partial L}{\partial y^N} \\
\end{bmatrix}
\begin{bmatrix}
w_1 &amp; w_2 &amp; \dots &amp; w_d
\end{bmatrix}
\]</span></p>
<p>In code: <code>inp.g = out.g @ w.T</code></p>
</section>
<section id="for-w" class="level4">
<h4 class="anchored" data-anchor-id="for-w">For <span class="math inline">\(W\)</span>‚Ä¶</h4>
<p>Starting with a single parameter, <span class="math inline">\(w_j\)</span>:</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial L}{\partial w_j} &amp;= \frac{\partial L}{\partial Y} \cdot \frac{\partial Y}{\partial w_j} \\
                                &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k} \cdot \frac{\partial y^k}{\partial w_j} \\
                                &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k} \cdot \frac{\partial w_j x_j^k + b_j}{\partial w_j} \\
                                &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k} x_j^k
\end{align*}
\]</span></p>
<p>For all parameters, <span class="math inline">\(W\)</span>:</p>
<p><span class="math display">\[
\frac{\partial L}{\partial W} = \begin{bmatrix}
\frac{\partial L}{\partial w_{1}} \\
\frac{\partial L}{\partial w_{2}} \\
\vdots \\
\frac{\partial L}{\partial w_{d}}
\end{bmatrix} = \begin{bmatrix}
\sum_{k=1}^{N} \frac{\partial L}{\partial y^k} x_1^k \\
\sum_{k=1}^{N} \frac{\partial L}{\partial y^k} x_2^k \\
\vdots \\
\sum_{k=1}^{N} \frac{\partial L}{\partial y^k} x_d^k
\end{bmatrix}
= \begin{bmatrix}
\frac{\partial L}{\partial y^1} x_1^1 &amp;+ \dots &amp;+ \frac{\partial L}{\partial y^N} x_1^N \\
\frac{\partial L}{\partial y^1} x_2^1 &amp;+ \dots &amp;+ \frac{\partial L}{\partial y^N} x_2^N \\
\vdots &amp; \ddots &amp; \vdots \\
\frac{\partial L}{\partial y^1} x_d^1 &amp;+ \dots &amp;+ \frac{\partial L}{\partial y^N} x_d^N \\
\end{bmatrix} = \begin{bmatrix}
x_1^1 &amp; \dots &amp; x^{N}_1 \\
x_2^1 &amp; \dots &amp; x^{N}_2 \\
\vdots &amp; \ddots &amp; \vdots \\
x_d^1 &amp; \dots &amp; x^{N}_d
\end{bmatrix}  \begin{bmatrix}
\frac{\partial L}{\partial y_{1}} \\
\frac{\partial L}{\partial y_{2}} \\
\vdots \\
\frac{\partial L}{\partial y_{N}} \\
\end{bmatrix} = X^T \frac{\partial L}{\partial Y}
\]</span></p>
<p>In code: <code>w.g = inp.v.T @ out.g</code></p>
</section>
<section id="for-b" class="level4">
<h4 class="anchored" data-anchor-id="for-b">For <span class="math inline">\(B\)</span>‚Ä¶</h4>
<p><span class="math display">\[
\begin{align*}
\frac{\partial L}{\partial B} &amp;= \frac{\partial L}{\partial Y} \cdot \frac{\partial Y}{\partial B} \\
                              &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k} \cdot \frac{\partial y^k}{\partial B} \\
                              &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k} (1) \\
                               &amp;= \sum_{k=1}^{N} \frac{\partial L}{\partial y^k}
\end{align*}
\]</span></p>
<p>In code <code>b.g = out.g.sum(axis=0)</code></p>
<p>You can see that these derivation are similar to their single-variable counterparts (e.g.&nbsp;<span class="math inline">\(\frac{dL}{dm} = \frac{dL}{dy} \cdot \frac{dy}{dm} = \frac{dL}{dy} \cdot \frac{dmx+b}{dm}=\frac{dL}{dy}x\)</span>). However, the <strong>order</strong> of operations and the transposition is dictated by the matrix mathematics.</p>
<p>In code:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lin_grad(inp, out, w, b):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    inp.g <span class="op">=</span> out.g <span class="op">@</span> w.T</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    w.g <span class="op">=</span> inp.v.T <span class="op">@</span> out.g</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    b.g <span class="op">=</span> out.g.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Much credit for my understanding goes to <a href="https://nasheqlbrm.github.io/blog/posts/2021-11-13-backward-pass.html">this blog bost.</a></p>
</section>
</section>
<section id="relu" class="level3">
<h3 class="anchored" data-anchor-id="relu">ReLU</h3>
<p>For ReLU, we pass the upstream gradient downstream for any dimensions that contributed to the upstream signal. Note that this is an element-wise operation because the layer operates only on specific elements and has no global behavior.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu_grad(inp, out):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    inp.g <span class="op">=</span> (inp.value <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">float</span>) <span class="op">*</span> out.g</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Putting it all together:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># "Tensorize" the weights, biases and outputs</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>tensors <span class="op">=</span> (y_pred, W1, b1, l1, W0, b0, l0, X_trn)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>ty_pred, tW1, tb1, tl1, tW0, tb0, tl0, tX_trn <span class="op">=</span> <span class="bu">map</span>(T, tensors)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>mse_grad(ty_pred, y_true)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>ty_pred.g[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>array([[-0.00049577],
       [-0.00080577],
       [ 0.00094763],
       [ 0.00016918],
       [-0.00248921]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>mse_grad(ty_pred, y_true)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>lin_grad(tl1, ty_pred, tW1, tb1)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>relu_grad(tl0, tl1)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>lin_grad(tX_trn, tl0, tW0, tb0)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Verify with PyTorch</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Port layers</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>pt_lin0 <span class="op">=</span> nn.Linear(m, nh)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> pt_lin0.weight.data.dtype</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>pt_lin0.weight.data <span class="op">=</span> torch.from_numpy(tW0.v.T).to(dtype)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>pt_lin0.bias.data <span class="op">=</span> torch.from_numpy(tb0.v).to(dtype)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>pt_lin1 <span class="op">=</span> nn.Linear(nh, <span class="dv">1</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>pt_lin1.weight.data <span class="op">=</span> torch.from_numpy(tW1.T).to(dtype)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>pt_lin1.bias.data <span class="op">=</span> torch.from_numpy(tb1.v).to(dtype)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> pt_lin0(torch.from_numpy(X_trn).to(dtype))</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> F.relu(logits)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> pt_lin1(logits)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> F.mse_loss(</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    logits.squeeze(),</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    torch.from_numpy(y_true).<span class="bu">float</span>(),</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Backward pass</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w, b, layer <span class="kw">in</span> [</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    (tW0, tb0, pt_lin0),</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    (tW1, tb1, pt_lin1),</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>]:</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> torch.isclose(</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>        torch.from_numpy(w.g.T).<span class="bu">float</span>(),</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>        layer.weight.grad,</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>        atol<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>    ).<span class="bu">all</span>()</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> torch.isclose(</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>        torch.from_numpy(b.g.T).<span class="bu">float</span>(),</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>        layer.bias.grad,</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>        atol<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>    ).<span class="bu">all</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let‚Äôs refactor these as classes.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Module:</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, <span class="op">*</span>x):</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.inp <span class="op">=</span> x</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> <span class="va">self</span>.forward(<span class="op">*</span>x)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(<span class="va">self</span>.out, (np.ndarray,)):</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.out <span class="op">=</span> T(<span class="va">self</span>.out)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ReLu(Module):</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: T):</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> relu(x)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>        (x,) <span class="op">=</span> <span class="va">self</span>.inp</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        relu_grad(x, <span class="va">self</span>.out)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear(Module):</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, h_in, h_out):</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> T(np.random.randn(h_in, h_out))</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> T(np.zeros(h_out))</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> T(x <span class="op">@</span> <span class="va">self</span>.W.v <span class="op">+</span> <span class="va">self</span>.b.v)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>        (x,) <span class="op">=</span> <span class="va">self</span>.inp</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>        lin_grad(x, <span class="va">self</span>.out, <span class="va">self</span>.W, <span class="va">self</span>.b)</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MSE(Module):</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, y_pred, y_true):</span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ((y_pred.squeeze() <span class="op">-</span> y_true) <span class="op">**</span> <span class="dv">2</span>).mean()</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>        y_pred, y_true <span class="op">=</span> <span class="va">self</span>.inp</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>        mse_grad(y_pred, y_true)</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(Module):</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, layers, criterion):</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> layers</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion <span class="op">=</span> criterion</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, y_pred):</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers:</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> l(x)</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion(x, y_pred)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion.backward()</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">reversed</span>(<span class="va">self</span>.layers):</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>            l.backward()</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MLP([Linear(m, nh), ReLu(), Linear(nh, <span class="dv">1</span>)], criterion<span class="op">=</span>MSE())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>model(tX_trn, y_true)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>model.backward()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is quite a bit cleaner!</p>
<p>By the rules of FastAI, we can now use the <code>torch.nn.Module</code> classes which is the equivalent in PyTorch.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
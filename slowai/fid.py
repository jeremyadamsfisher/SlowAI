# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/17_fid.ipynb.

# %% auto 0
__all__ = ['BS', 'Hook', 'get_fid_logits', 'summarize', 'fid', 'kid', 'ImageEval']

# %% ../nbs/17_fid.ipynb 3
import math
import sys
from contextlib import contextmanager
from functools import partial
from pathlib import Path

import matplotlib.pyplot as plt
import minai as miniai
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torch.nn.functional as F
import torchvision.transforms as T
from glom import T as GT
from glom import glom
from IPython.utils import io
from scipy import linalg
from sklearn.decomposition import PCA
from torch import tensor
from torch.optim import lr_scheduler
from torchmetrics.classification import MulticlassAccuracy
from tqdm import tqdm

from slowai.augmentation import (
    GlobalAveragePooling,
    ResNetWithGlobalPooling,
    ResNetWithGlobalPoolingInitialConv,
)
from .ddpm import DDPM, get_dls
from slowai.learner import (
    DeviceCB,
    MetricsCB,
    ProgressCB,
    TrainLearner,
    batchify,
    def_device,
    fashion_mnist,
    show_images,
    to_cpu,
)
from .sgd import BatchSchedulerCB
from .utils import clean_mem, show_images

# %% ../nbs/17_fid.ipynb 4
BS = 256

# %% ../nbs/17_fid.ipynb 19
@contextmanager
def Hook(h):
    yield
    h.remove()


@torch.no_grad()
def get_fid_logits(model, xb, layer="pool"):
    feat = None

    def h(module, _, output):
        nonlocal feat
        feat = output

    with Hook(glom(model, layer).register_forward_hook(h)):
        model(xb)

    assert feat is not None
    return feat

# %% ../nbs/17_fid.ipynb 29
def summarize(X):
    # Note that we want the covariance between features, rather than the covariance
    # between examples, so it should be X.T.cov(). You could also specify (X.cov(rowvar=False))
    return X.mean(axis=0), X.T.cov()

# %% ../nbs/17_fid.ipynb 31
def fid(real, fake, bs=BS):
    (m0, c0), (m1, c1) = map(to_cpu, (real, fake))
    csr = linalg.sqrtm(c0 @ c1, bs).real  # Matrix square root
    csr = tensor(csr)
    fid_ = ((m0 - m1) ** 2).sum() + c0.trace() + c1.trace() - 2 * csr.trace()
    return fid_.item()

# %% ../nbs/17_fid.ipynb 39
def _squared_mmd(x, y):
    def k(a, b):
        return (a @ b.transpose(-2, -1) / a.shape[-1] + 1) ** 3

    m, n = x.shape[-2], y.shape[-2]
    kxx, kyy, kxy = k(x, x), k(y, y), k(x, y)
    kxx_sum = kxx.sum([-1, -2]) - kxx.diagonal(0, -1, -2).sum(-1)
    kyy_sum = kyy.sum([-1, -2]) - kyy.diagonal(0, -1, -2).sum(-1)
    kxy_sum = kxy.sum([-1, -2])
    return kxx_sum / m / (m - 1) + kyy_sum / n / (n - 1) - kxy_sum * 2 / m / n

# %% ../nbs/17_fid.ipynb 40
def kid(x, y, maxs=50):
    xs, ys = x.shape[0], y.shape[0]
    n = max(math.ceil(min(xs / maxs, ys / maxs)), 4)
    mmd = 0.0
    for i in range(n):
        cur_x = x[round(i * xs / n) : round((i + 1) * xs / n)]
        cur_y = y[round(i * ys / n) : round((i + 1) * ys / n)]
        mmd += _squared_mmd(cur_x, cur_y)
    return (mmd / n).item()

# %% ../nbs/17_fid.ipynb 43
class ImageEval:
    def __init__(self, inception, x_example, layer="pool", validate=None):
        self.validate = validate
        self.x_example = x_example
        self.inception = inception.to(def_device)
        self.layer = layer
        self.feats = self.featurize(x_example.to(def_device))
        self.summary = summarize(self.feats)

    def featurize(self, x):
        if self.validate is not None:
            self.validate(x)
        return get_fid_logits(self.inception, x.to(def_device), self.layer)

    def fid(self, x):
        assert x.shape[0] == self.x_example.shape[0]
        x = self.featurize(x)
        return fid(summarize(x), self.summary)

    def kid(self, x):
        return kid(self.featurize(x), self.feats)

    @classmethod
    def fashion_mnist(cls, fp="../models/fashion_mnist_classifier.pt", bs=512, tol=0.1):
        from slowai.augmentation import (
            GlobalAveragePooling,
            ResNetWithGlobalPoolingInitialConv,
        )

        def validate(x):
            assert -0.5 - tol <= x.min() and xb.max() <= 0.5 + tol

        dls = get_dls(bs)
        xb, _ = dls.peek()
        clf = torch.load(fp)
        return cls(clf, xb, validate=validate)

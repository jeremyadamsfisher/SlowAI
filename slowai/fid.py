# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/18_fid.ipynb.

# %% auto 0
__all__ = ['BS', 'Hook', 'get_global_average_pooling', 'summarize', 'fid', 'kid', 'ImageEval']

# %% ../nbs/18_fid.ipynb 3
import math
from contextlib import contextmanager
from functools import partial
from pathlib import Path

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import torch
import torch.nn.functional as F
import torchvision.transforms as T
from IPython.utils import io
from scipy import linalg
from sklearn.decomposition import PCA
from torch import tensor
from torch.optim import lr_scheduler
from torchmetrics.classification import MulticlassAccuracy
from tqdm import tqdm

from slowai.augmentation import (
    GlobalAveragePooling,
    ResNet,
    ResNetWithGlobalPooling,
    ResNetWithGlobalPoolingInitialConv,
)
from .ddpm import DDPM, fashion_unet, get_dls, train
from slowai.learner import (
    DeviceCB,
    MetricsCB,
    ProgressCB,
    TrainLearner,
    batchify,
    def_device,
    fashion_mnist,
    show_images,
    to_cpu,
)
from .sgd import BatchSchedulerCB
from .utils import clean_mem, get_grid, glomf, show_image, show_images

# %% ../nbs/18_fid.ipynb 4
BS = 512

# %% ../nbs/18_fid.ipynb 18
@contextmanager
def Hook(h):
    yield
    h.remove()


@torch.no_grad()
def get_global_average_pooling(model, xb):
    feat = None

    def h(module: GlobalAveragePooling, _, output):
        nonlocal feat
        feat = output

    with Hook(model.pool.register_forward_hook(h)):
        model(xb)

    assert feat is not None
    return feat

# %% ../nbs/18_fid.ipynb 27
def summarize(X):
    return X.mean(axis=0), X.cov()

# %% ../nbs/18_fid.ipynb 29
def fid(real, fake, bs=BS):
    (m0, c0), (m1, c1) = map(to_cpu, (real, fake))
    csr = linalg.sqrtm(c0 @ c1, bs).real  # Matrix square root
    csr = tensor(csr)
    fid_ = ((m0 - m1) ** 2).sum() + c0.trace() + c1.trace() - 2 * csr.trace()
    return fid_.item()

# %% ../nbs/18_fid.ipynb 34
def _squared_mmd(x, y):
    def k(a, b):
        return (a @ b.transpose(-2, -1) / a.shape[-1] + 1) ** 3

    m, n = x.shape[-2], y.shape[-2]
    kxx, kyy, kxy = k(x, x), k(y, y), k(x, y)
    kxx_sum = kxx.sum([-1, -2]) - kxx.diagonal(0, -1, -2).sum(-1)
    kyy_sum = kyy.sum([-1, -2]) - kyy.diagonal(0, -1, -2).sum(-1)
    kxy_sum = kxy.sum([-1, -2])
    return kxx_sum / m / (m - 1) + kyy_sum / n / (n - 1) - kxy_sum * 2 / m / n

# %% ../nbs/18_fid.ipynb 35
def kid(x, y, maxs=50):
    xs, ys = x.shape[0], y.shape[0]
    n = max(math.ceil(min(xs / maxs, ys / maxs)), 4)
    mmd = 0.0
    for i in range(n):
        cur_x = x[round(i * xs / n) : round((i + 1) * xs / n)]
        cur_y = y[round(i * ys / n) : round((i + 1) * ys / n)]
        mmd += _squared_mmd(cur_x, cur_y)
    return (mmd / n).item()

# %% ../nbs/18_fid.ipynb 38
class ImageEval:
    def __init__(self, inception, x_example):
        self.inception = inception.to(def_device)
        self.feats = self.featurize(x_example.to(def_device))
        self.summary = summarize(self.feats)

    def featurize(self, x):
        return get_global_average_pooling(self.inception, x.to(def_device))

    def fid(self, x):
        x = self.featurize(x)
        return fid(summarize(x), self.summary)

    def kid(self, x):
        return kid(self.featurize(x), self.feats)

    @classmethod
    def fashion_mnist(cls, fp="../models/fashion_mnist_classifier.pt", bs=512):
        from slowai.augmentation import (
            GlobalAveragePooling,
            ResNetWithGlobalPoolingInitialConv,
        )

        dls = get_dls(bs)
        xb, _ = dls.peek()
        clf = torch.load(fp)
        return cls(clf, xb)

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_cosine.ipynb.

# %% auto 0
__all__ = ['aesthetics', 'ᾱ', 'noisify', 'ContinuousDDPM', 'denoisify', 'ddpm', 'ddim_noisify', 'ddim']

# %% ../nbs/20_cosine.ipynb 4
import math
from functools import lru_cache, partial
from pathlib import Path

import matplotlib
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
from torch import tensor
from torch.optim import lr_scheduler
from tqdm import tqdm

from .augmentation import GlobalAveragePooling, ResNetWithGlobalPoolingInitialConv
from .ddim import fashion_unet
from .ddpm import DDPM, get_dls, train
from .fid import ImageEval
from slowai.learner import (
    Callback,
    DeviceCB,
    Learner,
    MetricsCB,
    ProgressCB,
    TrainCB,
    after,
    def_device,
    only,
)
from .sgd import BatchSchedulerCB
from .utils import show_images

# %% ../nbs/20_cosine.ipynb 5
def aesthetics():
    """Improve the look and feel of our visualizations"""
    plt.style.use("ggplot")
    matplotlib.rcParams["image.cmap"] = "gray_r"

# %% ../nbs/20_cosine.ipynb 8
@lru_cache
def ᾱ(t, reshape=True, device=def_device):
    assert (0 <= t).all() and (t <= 1).all()
    ᾱ_ = ((t * math.pi / 2).cos() ** 2).clamp(0.0, 0.999)
    if reshape:
        ᾱ_ = ᾱ_.reshape(-1, 1, 1, 1)
    return ᾱ_

# %% ../nbs/20_cosine.ipynb 11
def noisify(x_0, t=None):
    n, *_ = x_0.shape
    device = x_0.device

    if t is None:
        t = torch.rand((n,), device=device)

    # Sample 2D noise for each example in the batch
    ε = torch.randn(x_0.shape, device=device)

    # Add noise according to the equation in Algorithm 1, such
    # that the variance of the distribution does not change
    x_t = ᾱ(t).sqrt() * x_0 + (1 - ᾱ(t)).sqrt() * ε

    return ((x_t, t), ε)

# %% ../nbs/20_cosine.ipynb 13
class ContinuousDDPM(DDPM, order=after(DeviceCB)):
    def before_batch(self, learn):
        x_0, _ = learn.batch
        learn.batch = noisify(x_0)

    @only
    def predict(self, learn):
        (x_t, t), _ = learn.batch
        learn.preds = learn.model(x_t, t).sample

# %% ../nbs/20_cosine.ipynb 18
def denoisify(x_t, noise, t):
    return (x_t - (1 - ᾱ(t)).sqrt() * noise) / ᾱ(t).sqrt()

# %% ../nbs/20_cosine.ipynb 23
@torch.no_grad()
def ddpm(model, sz=(16, 1, 32, 32), device=def_device, n_steps=100):
    x_t = torch.randn(sz, device=device)
    ts = torch.linspace(1 - (1 / n_steps), 0, n_steps).to(device)
    for t, t_next in tqdm(zip(ts, ts[1:]), unit="time step", total=n_steps - 1):
        # Predict the noise for each example in the image
        noise_pred = model(x_t, t).sample

        # Predict the image without noise
        x_0_pred = denoisify(x_t, noise_pred, t)

        # Renoise
        (prev_sample, _), _ = noisify(x_0_pred, t_next)

        # Repeat
        x_t = prev_sample

    # At the last step, simply rescale and do not add noise
    t = tensor(0.0, device=device)
    x_0 = denoisify(x_t, model(x_t, t).sample, t)

    return x_t

# %% ../nbs/20_cosine.ipynb 26
def ddim_noisify(η, x_0_pred, noise_pred, t, t_next):
    σ_t = η * ((1 - ᾱ(t_next)) / (1 - ᾱ(t))).sqrt() * (1 - ᾱ(t) / ᾱ(t_next)).sqrt()
    ε_t = torch.randn(x_0_pred.shape).to(x_0_pred.device)
    x_t = (
        # Scale \hat{x}_0
        ᾱ(t_next).sqrt() * x_0_pred
        # Step towards x_{t-1}
        + (1 - ᾱ(t_next) - σ_t**2).sqrt() * noise_pred
    )
    # Add noise
    if t_next > 0:
        x_t += σ_t * ε_t
    return x_t

# %% ../nbs/20_cosine.ipynb 27
@torch.no_grad()
def ddim(
    model,
    sz=(16, 1, 32, 32),
    device=def_device,
    n_steps=100,
    eta=1.0,
    noisify=ddim_noisify,
):
    x_t = torch.randn(sz, device=device)
    ts = torch.linspace(1 - (1 / n_steps), 0, n_steps).to(device)
    for t, t_next in tqdm(zip(ts, ts[1:]), unit="time step", total=n_steps - 1):
        # Predict the noise for each example in the image
        noise_pred = model(x_t, t).sample

        # Predict the image without noise
        x_0_pred = denoisify(x_t, noise_pred, t)

        # Renoise, if needed
        prev_sample = ddim_noisify(eta, x_0_pred, noise_pred, t, t_next)

        # Repeat
        x_t = prev_sample

    x_0 = denoisify(x_t, noise_pred, t)

    return x_0
